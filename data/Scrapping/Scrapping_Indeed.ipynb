{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Projet Scraper indeed </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.indeed.fr/')\n",
    "browser.maximize_window()\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire un script de scraping sur indeed (https://www.indeed.fr/)  qui permette à l’user de spécifier le type d’annonces qu’il souhaite récupérer :\n",
    "-\tMétier (développeur, data scientist…)\n",
    "-\tType de contrat recherché (CDI, CDD, freelance…)\n",
    "-\tLieu de recherche (Paris, Toulouse, …)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metier(string):\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"text-input-what\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(2)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    sleep(2)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        \n",
    "\n",
    "def Localisation(string):\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"where\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(2)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    sleep(2)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def Type_Contrat(string):\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if string.lower() == 'cdi':      \n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[1]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps plein':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[2]/a/span[1]\").click()\n",
    "    if string.lower() == 'stage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[3]/a/span[1]\").click()\n",
    "    if string.lower() == 'cdd':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[4]/a/span[1]\").click()\n",
    "    if string.lower() == 'apprentissage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[5]/a/span[1]\").click()\n",
    "    if string.lower() == 'contrat pro':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[6]/a/span[1]\").click()\n",
    "    if string.lower() == 'freelance / indépendant':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[7]/a/span[1]\").click()\n",
    "    if string.lower() == 'intérim':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[8]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps partiel':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[9]/a/span[1]\").click()    \n",
    "    sleep(2)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def Debug_pop():\n",
    "    sleep(2)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les infos à scraper :\n",
    "-\tTitre\n",
    "-\tNom de la boite\n",
    "-\tAdresse\n",
    "-\tSalaire\n",
    "-\tDescriptif du poste\n",
    "-\tDate de publication de l’annonce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brow//*[@id=\"distance_selector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var_metier = input(\"Enter le métier recherché\")\n",
    "#var_localisation = input(\"Entrer la localistaion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_metier = \"'data analyst'\"\n",
    "var_localisation = 'meaux'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liste  à remplir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metier(var_metier)\n",
    "Localisation(var_localisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation des listes vides pour chaque colonne**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "Titre = []\n",
    "Nom_Entreprise = []\n",
    "Adresse = []\n",
    "Salaire = []\n",
    "Descriptif_du_poste = []\n",
    "Date_de_publication = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    Debug_pop()\n",
    "    annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "    for i in range(0,len(annonces)):\n",
    "        try:\n",
    "            titre = annonces[i].find_element_by_class_name('title')\n",
    "            Titre.append(titre.text)\n",
    "        except:\n",
    "            Titre.append('vide')\n",
    "        try:\n",
    "            nom = annonces[i].find_element_by_class_name('company')\n",
    "            Nom_Entreprise.append(nom.text)\n",
    "\n",
    "        except:\n",
    "            Nom_Entreprise.append('vide')\n",
    "        try:\n",
    "            adresse= annonces[i].find_element_by_class_name('location')\n",
    "            Adresse.append(adresse.text)\n",
    "        except:\n",
    "            Adresse.append('vide')\n",
    "        try:\n",
    "            date = annonces[i].find_element_by_class_name('date')\n",
    "            Date_de_publication.append(date.text)\n",
    "\n",
    "        except:\n",
    "            Date_de_publication.append('vide')\n",
    "        try:\n",
    "            salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "            Salaire.append(salaire.text)\n",
    "        except:\n",
    "            Salaire.append('vide')\n",
    "        try:\n",
    "            annonces[i].find_element_by_class_name('title').click()\n",
    "            Debug_pop()\n",
    "            descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "            Descriptif_du_poste.append(descriptif.text)\n",
    "        except:\n",
    "            Descriptif_du_poste.append('vide')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "        sleep(2)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnaire = {\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "                \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\n",
    "                \"Date_de_publication\":Date_de_publication,\n",
    "                \"métier_sc\": var_metier,\"loc_sc\":var_localisation,\"date_sc\": now.strftime(\"%d/%m/%Y\") ,\n",
    "                \"heure_sc\": now.strftime(\"%H:%M:%S\")}\n",
    "df = pd.DataFrame(dictionnaire) \n",
    "\n",
    "df.to_csv('indeed_jobs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Nom_Entreprise</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Salaire</th>\n",
       "      <th>Descriptif_du_poste</th>\n",
       "      <th>Date_de_publication</th>\n",
       "      <th>métier_sc</th>\n",
       "      <th>loc_sc</th>\n",
       "      <th>date_sc</th>\n",
       "      <th>heure_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INGÉNIEUR DATA SCIENTIST EXPÉRIMENTÉ (H/F)</td>\n",
       "      <td>sii</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nDescription du poste :\\nrattach...</td>\n",
       "      <td>vide</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ingénieur Data Scientist H/F</td>\n",
       "      <td>EPSILON-ALCEN</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>30 000 € - 50 000 € par an</td>\n",
       "      <td>Toulouse (31)\\nCDI\\n30 000 € - 50 000 € par an...</td>\n",
       "      <td>il y a 15 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Ingénieur Data Scientist Junior H/F</td>\n",
       "      <td>CS Communication &amp; Systèmes</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nCDI\\nDESCRIPTION DE L'OFFRE\\nCS...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stage en data scientist H/F</td>\n",
       "      <td>Altran</td>\n",
       "      <td>Blagnac (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Blagnac (31)\\nStage\\nAu sein de l'entité Digit...</td>\n",
       "      <td>il y a 2 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DATA SCIENTIST (H/F)</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nAPSYS SAS\\nAirbus is a global l...</td>\n",
       "      <td>il y a 29 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Technicien Support Applicatif F/H</td>\n",
       "      <td>KENT</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nCDI\\nMissions : Kent vous propo...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>Senior Backend Developer (f/m/x) (relocated to...</td>\n",
       "      <td>Avira Operations GmbH &amp; Co. KG</td>\n",
       "      <td>France</td>\n",
       "      <td>vide</td>\n",
       "      <td>France\\nSenior Backend Developer (f/m/x)\\nLoca...</td>\n",
       "      <td>vide</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Développeur Front End (H/F)</td>\n",
       "      <td>NextGen RH</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nPrésentation\\nNEXTGEN RH est un...</td>\n",
       "      <td>il y a 8 mois</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>Persuaders RH</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>vide</td>\n",
       "      <td>Occitanie\\nEntreprise\\nL’entreprise pour laque...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Stage ingénieur Traitement de signal embarqué ...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>vide</td>\n",
       "      <td>Occitanie\\nStage\\nDescription de l’entreprise\\...</td>\n",
       "      <td>il y a 23 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Titre  \\\n",
       "0          INGÉNIEUR DATA SCIENTIST EXPÉRIMENTÉ (H/F)   \n",
       "1                        Ingénieur Data Scientist H/F   \n",
       "2                 Ingénieur Data Scientist Junior H/F   \n",
       "3                         Stage en data scientist H/F   \n",
       "4                                DATA SCIENTIST (H/F)   \n",
       "..                                                ...   \n",
       "62                  Technicien Support Applicatif F/H   \n",
       "63  Senior Backend Developer (f/m/x) (relocated to...   \n",
       "64                        Développeur Front End (H/F)   \n",
       "65                                 Data Scientist F/H   \n",
       "66  Stage ingénieur Traitement de signal embarqué ...   \n",
       "\n",
       "                    Nom_Entreprise        Adresse                     Salaire  \\\n",
       "0                              sii  Toulouse (31)                        vide   \n",
       "1                    EPSILON-ALCEN  Toulouse (31)  30 000 € - 50 000 € par an   \n",
       "2      CS Communication & Systèmes  Toulouse (31)                        vide   \n",
       "3                           Altran   Blagnac (31)                        vide   \n",
       "4                           Airbus  Toulouse (31)                        vide   \n",
       "..                             ...            ...                         ...   \n",
       "62                            KENT  Toulouse (31)                        vide   \n",
       "63  Avira Operations GmbH & Co. KG         France                        vide   \n",
       "64                      NextGen RH  Toulouse (31)                        vide   \n",
       "65                   Persuaders RH      Occitanie                        vide   \n",
       "66                       Capgemini      Occitanie                        vide   \n",
       "\n",
       "                                  Descriptif_du_poste Date_de_publication  \\\n",
       "0   Toulouse (31)\\nDescription du poste :\\nrattach...                vide   \n",
       "1   Toulouse (31)\\nCDI\\n30 000 € - 50 000 € par an...     il y a 15 jours   \n",
       "2   Toulouse (31)\\nCDI\\nDESCRIPTION DE L'OFFRE\\nCS...    il y a 30+ jours   \n",
       "3   Blagnac (31)\\nStage\\nAu sein de l'entité Digit...      il y a 2 jours   \n",
       "4   Toulouse (31)\\nAPSYS SAS\\nAirbus is a global l...     il y a 29 jours   \n",
       "..                                                ...                 ...   \n",
       "62  Toulouse (31)\\nCDI\\nMissions : Kent vous propo...    il y a 30+ jours   \n",
       "63  France\\nSenior Backend Developer (f/m/x)\\nLoca...                vide   \n",
       "64  Toulouse (31)\\nPrésentation\\nNEXTGEN RH est un...       il y a 8 mois   \n",
       "65  Occitanie\\nEntreprise\\nL’entreprise pour laque...    il y a 30+ jours   \n",
       "66  Occitanie\\nStage\\nDescription de l’entreprise\\...     il y a 23 jours   \n",
       "\n",
       "         métier_sc    loc_sc     date_sc  heure_sc  \n",
       "0   data scientist  toulouse  03/10/2019  10:29:09  \n",
       "1   data scientist  toulouse  03/10/2019  10:29:09  \n",
       "2   data scientist  toulouse  03/10/2019  10:29:09  \n",
       "3   data scientist  toulouse  03/10/2019  10:29:09  \n",
       "4   data scientist  toulouse  03/10/2019  10:29:09  \n",
       "..             ...       ...         ...       ...  \n",
       "62  data scientist  toulouse  03/10/2019  10:29:09  \n",
       "63  data scientist  toulouse  03/10/2019  10:29:09  \n",
       "64  data scientist  toulouse  03/10/2019  10:29:09  \n",
       "65  data scientist  toulouse  03/10/2019  10:29:09  \n",
       "66  data scientist  toulouse  03/10/2019  10:29:09  \n",
       "\n",
       "[67 rows x 10 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='localhost', port=27017)\n",
    "db=client.tech_jobs\n",
    "collection = db.indeed_jobs.insert_many(df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(db.indeed_jobs.find()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dates(df) :\n",
    "#     process dates\n",
    "    df_days = df[df.Date_de_publication.str.contains('jour')]\n",
    "    df_months = df[df.Date_de_publication.str.contains('mois')]\n",
    "    d_date_list = []\n",
    "    m_date_list = []\n",
    "    for ele in df_days['Date_de_publication'] :\n",
    "        nb_days = int(re.findall(\"[0-9]+\", ele)[0])\n",
    "        date = (now - timedelta(days=nb_days)).strftime(\"%d/%m/%Y\")\n",
    "        d_date_list.append(date)\n",
    "    for ele in df_months['Date_de_publication'] :\n",
    "        nb_months = int(re.findall(\"[0-9]+\", ele)[0])\n",
    "        date = (now - timedelta(nb_months*365/12)).strftime(\"%d/%m/%Y\")\n",
    "        m_date_list.append(date)\n",
    "    df_days['Date'] = d_date_list\n",
    "    df_months['Date'] = m_date_list\n",
    "    return df_days, df_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\Programs\\Miniconda\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\marie\\Programs\\Miniconda\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Nom_Entreprise</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Salaire</th>\n",
       "      <th>Descriptif_du_poste</th>\n",
       "      <th>Date_de_publication</th>\n",
       "      <th>métier_sc</th>\n",
       "      <th>loc_sc</th>\n",
       "      <th>date_sc</th>\n",
       "      <th>heure_sc</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INGÉNIEUR DATA SCIENTIST EXPÉRIMENTÉ (H/F)</td>\n",
       "      <td>sii</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nDescription du poste :\\nrattach...</td>\n",
       "      <td>vide</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ingénieur Data Scientist H/F</td>\n",
       "      <td>EPSILON-ALCEN</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>30 000 € - 50 000 € par an</td>\n",
       "      <td>Toulouse (31)\\nCDI\\n30 000 € - 50 000 € par an...</td>\n",
       "      <td>il y a 15 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Ingénieur Data Scientist Junior H/F</td>\n",
       "      <td>CS Communication &amp; Systèmes</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nCDI\\nDESCRIPTION DE L'OFFRE\\nCS...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stage en data scientist H/F</td>\n",
       "      <td>Altran</td>\n",
       "      <td>Blagnac (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Blagnac (31)\\nStage\\nAu sein de l'entité Digit...</td>\n",
       "      <td>il y a 2 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DATA SCIENTIST (H/F)</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nAPSYS SAS\\nAirbus is a global l...</td>\n",
       "      <td>il y a 29 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Technicien Support Applicatif F/H</td>\n",
       "      <td>KENT</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nCDI\\nMissions : Kent vous propo...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>Senior Backend Developer (f/m/x) (relocated to...</td>\n",
       "      <td>Avira Operations GmbH &amp; Co. KG</td>\n",
       "      <td>France</td>\n",
       "      <td>vide</td>\n",
       "      <td>France\\nSenior Backend Developer (f/m/x)\\nLoca...</td>\n",
       "      <td>vide</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Développeur Front End (H/F)</td>\n",
       "      <td>NextGen RH</td>\n",
       "      <td>Toulouse (31)</td>\n",
       "      <td>vide</td>\n",
       "      <td>Toulouse (31)\\nPrésentation\\nNEXTGEN RH est un...</td>\n",
       "      <td>il y a 8 mois</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>Persuaders RH</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>vide</td>\n",
       "      <td>Occitanie\\nEntreprise\\nL’entreprise pour laque...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Stage ingénieur Traitement de signal embarqué ...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>vide</td>\n",
       "      <td>Occitanie\\nStage\\nDescription de l’entreprise\\...</td>\n",
       "      <td>il y a 23 jours</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>toulouse</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>10:29:09</td>\n",
       "      <td>2019-10-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Titre  \\\n",
       "0          INGÉNIEUR DATA SCIENTIST EXPÉRIMENTÉ (H/F)   \n",
       "1                        Ingénieur Data Scientist H/F   \n",
       "2                 Ingénieur Data Scientist Junior H/F   \n",
       "3                         Stage en data scientist H/F   \n",
       "4                                DATA SCIENTIST (H/F)   \n",
       "..                                                ...   \n",
       "62                  Technicien Support Applicatif F/H   \n",
       "63  Senior Backend Developer (f/m/x) (relocated to...   \n",
       "64                        Développeur Front End (H/F)   \n",
       "65                                 Data Scientist F/H   \n",
       "66  Stage ingénieur Traitement de signal embarqué ...   \n",
       "\n",
       "                    Nom_Entreprise        Adresse                     Salaire  \\\n",
       "0                              sii  Toulouse (31)                        vide   \n",
       "1                    EPSILON-ALCEN  Toulouse (31)  30 000 € - 50 000 € par an   \n",
       "2      CS Communication & Systèmes  Toulouse (31)                        vide   \n",
       "3                           Altran   Blagnac (31)                        vide   \n",
       "4                           Airbus  Toulouse (31)                        vide   \n",
       "..                             ...            ...                         ...   \n",
       "62                            KENT  Toulouse (31)                        vide   \n",
       "63  Avira Operations GmbH & Co. KG         France                        vide   \n",
       "64                      NextGen RH  Toulouse (31)                        vide   \n",
       "65                   Persuaders RH      Occitanie                        vide   \n",
       "66                       Capgemini      Occitanie                        vide   \n",
       "\n",
       "                                  Descriptif_du_poste Date_de_publication  \\\n",
       "0   Toulouse (31)\\nDescription du poste :\\nrattach...                vide   \n",
       "1   Toulouse (31)\\nCDI\\n30 000 € - 50 000 € par an...     il y a 15 jours   \n",
       "2   Toulouse (31)\\nCDI\\nDESCRIPTION DE L'OFFRE\\nCS...    il y a 30+ jours   \n",
       "3   Blagnac (31)\\nStage\\nAu sein de l'entité Digit...      il y a 2 jours   \n",
       "4   Toulouse (31)\\nAPSYS SAS\\nAirbus is a global l...     il y a 29 jours   \n",
       "..                                                ...                 ...   \n",
       "62  Toulouse (31)\\nCDI\\nMissions : Kent vous propo...    il y a 30+ jours   \n",
       "63  France\\nSenior Backend Developer (f/m/x)\\nLoca...                vide   \n",
       "64  Toulouse (31)\\nPrésentation\\nNEXTGEN RH est un...       il y a 8 mois   \n",
       "65  Occitanie\\nEntreprise\\nL’entreprise pour laque...    il y a 30+ jours   \n",
       "66  Occitanie\\nStage\\nDescription de l’entreprise\\...     il y a 23 jours   \n",
       "\n",
       "         métier_sc    loc_sc     date_sc  heure_sc       Date  \n",
       "0   data scientist  toulouse  03/10/2019  10:29:09        NaT  \n",
       "1   data scientist  toulouse  03/10/2019  10:29:09 2019-09-18  \n",
       "2   data scientist  toulouse  03/10/2019  10:29:09 2019-03-09  \n",
       "3   data scientist  toulouse  03/10/2019  10:29:09 2019-01-10  \n",
       "4   data scientist  toulouse  03/10/2019  10:29:09 2019-04-09  \n",
       "..             ...       ...         ...       ...        ...  \n",
       "62  data scientist  toulouse  03/10/2019  10:29:09 2019-03-09  \n",
       "63  data scientist  toulouse  03/10/2019  10:29:09        NaT  \n",
       "64  data scientist  toulouse  03/10/2019  10:29:09 2019-02-02  \n",
       "65  data scientist  toulouse  03/10/2019  10:29:09 2019-03-09  \n",
       "66  data scientist  toulouse  03/10/2019  10:29:09 2019-10-09  \n",
       "\n",
       "[67 rows x 11 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_dates(df, process_dates()) :    \n",
    "#     add dates to the original dataframe\n",
    "    df[\"Date\"] = 'vide'\n",
    "    df_days, df_months = process_dates()\n",
    "    df.update(df_days)\n",
    "    df.update(df_months)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    return df\n",
    "add_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MODELE REG LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Programs\\Miniconda\\envs\\machinelearning\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-0cad0ee4f9c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Salaire\"\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'vide'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Programs\\Miniconda\\envs\\machinelearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Miniconda\\envs\\machinelearning\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "df_process = df[df[\"Salaire\" != 'vide']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
