{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Projet Scraper indeed </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Librairies </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "now = datetime.now()\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from time import sleep\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Fonctions scrapping  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debug_pop():\n",
    "    ''' Fonction permettant le debug lors d un POP'''\n",
    "    sleep(0.5)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def Metier(string):\n",
    "    ''' \n",
    "    Fonction permettant de scrapper le métier choisi\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()   \n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"text-input-what\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(0.5)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    Debug_pop()\n",
    "    browser.find_element_by_xpath('//*[@id=\"refineresults\"]/div[1]/span[2]/a').click()\n",
    "    Debug_pop()\n",
    "\n",
    "        \n",
    "\n",
    "def Localisation(string):\n",
    "    ''' \n",
    "    Fonction permettant de scrapper la localisation choisie\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()\n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"where\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(2)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    Debug_pop()\n",
    "    \n",
    "def Type_Contrat(string):\n",
    "    \n",
    "    ''' \n",
    "    Fonction permettant de scrapper le contrat choisi\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()\n",
    "    \n",
    "    if string.lower() == 'cdi':      \n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[1]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps plein':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[2]/a/span[1]\").click()\n",
    "    if string.lower() == 'stage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[3]/a/span[1]\").click()\n",
    "    if string.lower() == 'cdd':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[4]/a/span[1]\").click()\n",
    "    if string.lower() == 'apprentissage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[5]/a/span[1]\").click()\n",
    "    if string.lower() == 'contrat pro':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[6]/a/span[1]\").click()\n",
    "    if string.lower() == 'freelance / indépendant':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[7]/a/span[1]\").click()\n",
    "    if string.lower() == 'intérim':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[8]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps partiel':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[9]/a/span[1]\").click()    \n",
    "    Debug_pop()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Scrappeur(metier,localisation):\n",
    "    \n",
    "    ''' \n",
    "     Focntion permettant de scrapper les pages \n",
    "    '''\n",
    "    \n",
    "    browser.get('https://www.indeed.fr/')\n",
    "    browser.maximize_window()\n",
    "    \n",
    "\n",
    "    \n",
    "    Metier(metier)\n",
    "    Localisation(localisation)\n",
    "    \n",
    "    #Titre = []\n",
    "    #Nom_Entreprise = []\n",
    "    #Adresse = []\n",
    "    #Salaire = []\n",
    "    #Descriptif_du_poste = []\n",
    "    #Date_de_publication = []\n",
    "    #Identifiant = []\n",
    "\n",
    "\n",
    "    while True:\n",
    "        Debug_pop()\n",
    "        annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "        for i in range(0,len(annonces)):\n",
    "            try:\n",
    "                titre = annonces[i].find_element_by_class_name('title')\n",
    "                Titre.append(titre.text)\n",
    "            except:\n",
    "                Titre.append('vide')\n",
    "            try:\n",
    "                nom = annonces[i].find_element_by_class_name('company')\n",
    "                Nom_Entreprise.append(nom.text)\n",
    "\n",
    "            except:\n",
    "                Nom_Entreprise.append('vide')\n",
    "            try:\n",
    "                adresse= annonces[i].find_element_by_class_name('location')\n",
    "                Adresse.append(adresse.text)\n",
    "            except:\n",
    "                Adresse.append('vide')\n",
    "            try:\n",
    "                date = annonces[i].find_element_by_class_name('date')\n",
    "                Date_de_publication.append(date.text)\n",
    "\n",
    "            except:\n",
    "                Date_de_publication.append('vide')\n",
    "            try:\n",
    "                salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "                Salaire.append(salaire.text)\n",
    "            except:\n",
    "                Salaire.append('vide')\n",
    "                \n",
    "            try:\n",
    "                annonces[i].find_element_by_class_name('title').click()\n",
    "                Debug_pop()\n",
    "                descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "                Descriptif_du_poste.append(descriptif.text)\n",
    "\n",
    "\n",
    "            except:\n",
    "                Descriptif_du_poste.append('vide')\n",
    "                \n",
    "            try:\n",
    "                    identifiant = browser.current_url\n",
    "                    pos1 = identifiant.find(\"vjk\")\n",
    "                    identifiant = identifiant[pos1:]\n",
    "                    Identifiant.append(identifiant)\n",
    "            except:\n",
    "                    Identifiant.append('vide')\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "            #for i in browser.find_elements_by_class_name(\"np\"):\n",
    "               # if i.text == 'Suivant »':\n",
    "                 #   i.click()\n",
    "        except:\n",
    "            break\n",
    "    df = pd.DataFrame(dictionnaire) \n",
    "    \n",
    "    \n",
    "    #dictionnaire = {\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "    #            \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\n",
    "    #            \"Date_de_publication\":Date_de_publication,\"Date\":Correction_date(Date_de_publication),\n",
    "    #            \"métier_sc\": metier,\"loc_sc\":localisation,\"Date_sc\": now.strftime(\"%d/%m/%Y\") ,\n",
    "    #            #\"heure_sc\": now.strftime(\"%H:%M:%S\"),\n",
    "    #            \"Identifiant\": Identifiant}\n",
    "\n",
    "    #df = pd.DataFrame(dictionnaire) \n",
    "    ##name_csv = f\"indeed_{metier}_{localisation}.csv\"\n",
    "    #df.to_csv(\"indeed_data_engineer_Nantes.csv\",index=False)\n",
    "    #return df\n",
    "    \n",
    "\n",
    "def Relance():\n",
    "    \n",
    "    while True:\n",
    "        Debug_pop()\n",
    "        annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "        for i in range(0,len(annonces)):\n",
    "            \n",
    "            try:\n",
    "                titre = annonces[i].find_element_by_class_name('title')\n",
    "                Titre.append(titre.text)\n",
    "            except:\n",
    "                Titre.append('vide')\n",
    "            try:\n",
    "                nom = annonces[i].find_element_by_class_name('company')\n",
    "                Nom_Entreprise.append(nom.text)\n",
    "\n",
    "            except:\n",
    "                Nom_Entreprise.append('vide')\n",
    "            try:\n",
    "                adresse= annonces[i].find_element_by_class_name('location')\n",
    "                Adresse.append(adresse.text)\n",
    "            except:\n",
    "                Adresse.append('vide')\n",
    "            try:\n",
    "                date = annonces[i].find_element_by_class_name('date')\n",
    "                Date_de_publication.append(date.text)\n",
    "\n",
    "            except:\n",
    "                Date_de_publication.append('vide')\n",
    "            try:\n",
    "                salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "                Salaire.append(salaire.text)\n",
    "            except:\n",
    "                Salaire.append('vide')\n",
    "\n",
    "            try:\n",
    "                annonces[i].find_element_by_class_name('title').click()\n",
    "                Debug_pop()\n",
    "                descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "                Descriptif_du_poste.append(descriptif.text)\n",
    "\n",
    "\n",
    "            except:\n",
    "                Descriptif_du_poste.append('vide')\n",
    "\n",
    "            try:\n",
    "                    identifiant = browser.current_url\n",
    "                    pos1 = identifiant.find(\"vjk\")\n",
    "                    identifiant = identifiant[pos1:]\n",
    "                    Identifiant.append(identifiant)\n",
    "            except:\n",
    "                    Identifiant.append('vide')\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "            \n",
    "        except:\n",
    "            break\n",
    "    df = pd.DataFrame(dictionnaire) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Fonctions preprocessing  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Occurence_regex_des(regex):\n",
    "    liste = []\n",
    "    for i in df['Descriptif_du_poste']:\n",
    "        liste.append(re.findall(regex,i))\n",
    "    cpt = 0\n",
    "    for i in liste:\n",
    "        if len(i) > 0:\n",
    "            cpt+= 1\n",
    "    print(f\"récupération de : {cpt} parmi {len(df['Descriptif_du_poste'])} = {round(cpt/len(df['Descriptif_du_poste'])*100,2) }\")\n",
    "    return liste     \n",
    "    \n",
    "def Recup_date(liste1,liste2):\n",
    "    \n",
    "    liste_corr = []\n",
    "    for i,j in zip(liste1,liste2):\n",
    "        if (i == 'vide') and (re.search('(il y a) (\\d+)(.*)(jour)',j)):\n",
    "            \n",
    "            temp = re.findall('(il y a) (\\d+)(.*)(jour)',j)[0]\n",
    "            temp = ' '.join(temp)\n",
    "            liste_corr.append(temp)\n",
    "            \n",
    "            \n",
    "        elif (i == \"vide\") and (re.search('(il y a) (\\d+)(.*)(mois)',j)):\n",
    "            \n",
    "            temp = re.findall('(il y a) (\\d+)(.*)(mois)',j)[0]\n",
    "            temp = ' '.join(temp)\n",
    "            liste_corr.append(temp)\n",
    "\n",
    "\n",
    "        else:\n",
    "            liste_corr.append(i)\n",
    "    \n",
    "    liste_corr  = [str(x) for x in liste_corr]\n",
    "    liste_corr  = [s.replace('+', '') for s in liste_corr]\n",
    "\n",
    "    return liste_corr    \n",
    "\n",
    "def Correction_date(liste):\n",
    "    ''' \n",
    "    Fonction permettant de corriger les dates de publications \n",
    "    example : il y a 2 jours en 05/10/2019 si now = 07/10/2019  \n",
    "    input = liste\n",
    "    output = liste\n",
    "        \n",
    "    '''\n",
    "    liste_corr = []\n",
    "    for i in liste:\n",
    " \n",
    "            \n",
    "        jours = 0\n",
    "        mois = 0\n",
    "        annees = 0 \n",
    "       \n",
    " \n",
    "        if (\"Publiée à l'instant\" or \"Aujourd'hui\") in i:\n",
    "            \n",
    "            d = datetime.today()\n",
    "            d =d.strftime(\"%d/%m/%Y\")\n",
    "            #print(i,',',d,'index = ',liste.index(i))\n",
    "            liste_corr.append(d)\n",
    "            \n",
    "        elif re.search(' jours?',i): \n",
    "                \n",
    "                day = int(re.findall('\\d+',i)[0])\n",
    "                d = datetime.today() + relativedelta(days=-day)\n",
    "                d =d.strftime(\"%d/%m/%Y\")\n",
    "                #print(i,'day = ',day,',',d,'index = ',liste.index(i))\n",
    "                liste_corr.append(d)\n",
    "\n",
    "                    \n",
    "        elif 'mois' in i :\n",
    "            month =  int(re.findall('\\d+',i)[0])\n",
    "            d = datetime.today() + relativedelta(months=-month)\n",
    "            d =d.strftime(\"%d/%m/%Y\")\n",
    "            #print(i,'mois = ',month,',',d,'index = ',liste.index(i))\n",
    "            liste_corr.append(d)\n",
    "        else:\n",
    "            d= i\n",
    "            liste_corr.append(d)\n",
    "\n",
    "      \n",
    "    return liste_corr\n",
    "\n",
    "\n",
    "def Calcul_mod(column):\n",
    "    \n",
    "    vide = df[column] == 'vide'\n",
    "    non_vide = df[column] != 'vide'\n",
    "    null = pd.isnull(df[column])\n",
    "    nb_vide = df[column][vide].count()\n",
    "    nb_non_vide = df[column][non_vide].count()\n",
    "    nb_null = df[column][null].count()\n",
    "    result = pd.DataFrame({\"column\":column,\n",
    "              \"vide\": [nb_vide],\n",
    "              \"non_vide\": [nb_non_vide],\n",
    "              \"null\": [nb_null]})\n",
    "    \n",
    "    return result \n",
    "          \n",
    "def Recup_exp(string):\n",
    "    string = str(string)\n",
    "    debutants = 'junior|débutant| debutant'\n",
    "    confirmes = 'confirmé'\n",
    "    senior ='senior'\n",
    "    \n",
    "    if re.search(debutants,string.lower()):\n",
    "        string = 'junior'\n",
    "    elif re.search(confirmes,string.lower()):\n",
    "        string = 'confirmé'\n",
    "        \n",
    "    elif re.search('senior',string.lower()):\n",
    "        string = 'senior'\n",
    "    else:\n",
    "        string = 'vide'\n",
    "    return string\n",
    "\n",
    "def Recup_exp_des(string):\n",
    "    string = str(string)\n",
    "    regex = \"(?<=avec )(\\d+)(?= ans | années d'expériences)| (\\d+)(?= ans .Souhaité. ) |(?<=Nombre d’année d.exp...)(.*)(?= ans|années)\"\n",
    "\n",
    "    \n",
    "    if re.search(regex,string.lower()):\n",
    "        string = re.findall(regex,string.lower())\n",
    "\n",
    "    else:\n",
    "        string = 'vide'\n",
    "    return string\n",
    "\n",
    "def Recup_type_contrat(string):\n",
    "    string = str(string)\n",
    "    string = string.lower()\n",
    "    cdi = \"cdi\"\n",
    "    cdd = 'cdd'\n",
    "    stage = 'stage'\n",
    "    apprentissage = 'apprentissage'\n",
    "    contrat_pro = 'contrat pro'\n",
    "    interim = 'intérim'\n",
    "    freelance_independant = 'freelance / indépendant'\n",
    "    \n",
    "    if re.search(cdi,string):\n",
    "        string = 'cdi'\n",
    "    elif re.search(cdd,string):\n",
    "        string = 'cdd'\n",
    "    elif re.search(stage,string):\n",
    "        string = 'stage'\n",
    "        \n",
    "    elif re.search(apprentissage,string):\n",
    "        string = 'apprentissage'\n",
    "    elif re.search(contrat_pro,string):\n",
    "        string = 'contrat_pro'\n",
    "    elif re.search(interim,string):\n",
    "        string = 'intérim'\n",
    "    elif re.search(freelance_independant,string):\n",
    "        string = 'freelance'\n",
    "    else:\n",
    "        string = 'vide'\n",
    "    return string         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Scrapping </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titre = []\n",
    "Nom_Entreprise = []\n",
    "Adresse = []\n",
    "Salaire = []\n",
    "Descriptif_du_poste = []\n",
    "Date_de_publication = []\n",
    "Identifiant = []\n",
    "metier = 'devops'\n",
    "loc = 'Paris'\n",
    "\n",
    "dictionnaire = {\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "                \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\n",
    "                \"Date_de_publication\":Date_de_publication,\"métier_sc\": metier,\n",
    "                \"loc_sc\":loc,\"Date_sc\": now.strftime(\"%d/%m/%Y\") ,\n",
    "                #\"heure_sc\": now.strftime(\"%H:%M:%S\"),\n",
    "                \"Identifiant\": Identifiant}\n",
    "\n",
    "df = pd.DataFrame(dictionnaire) \n",
    "\n",
    "metiers = {\n",
    "           'Data_scientist': 'title:(\"data scientist\" or \"data science\" or \"machine learning\" or \"deep learning\")',\n",
    "           'Data_analyst'  : 'title:(\"data analyst\" or \"data analyste\" or \"data analysis\" or \"data analytics\")',\n",
    "           'Data_architect': 'title:(\"data architecte\" or \"data architect\")',\n",
    "           'Data_engineer' : 'title:(\"data engineer\" )',\n",
    "           'Big_data'      : 'title:(\"big data\")',\n",
    "           'Autres_metiers_data' : 'title:data -scientist -analyst -engineer -\"big data\" -architecte -bi -\"business intelligence\"',\n",
    "           'developpeur':     'title:(développeur or developer) -data -business -affaire -toiles -bi -\"business intelligence\"',\n",
    "           'BI'          :    'title:(BI or \"business intelligence\")',\n",
    "           'devops':   'title: devops -développeur -developer -developpeur'\n",
    "           \n",
    "           }\n",
    "\n",
    "\n",
    "\n",
    "Localisations = [\"Paris\",\"Lyon\", \"Toulouse\", \"Nantes\",\"Bordeaux\"]\n",
    "#columns = [Titre,Nom_Entreprise,Adresse,Salaire,Descriptif_du_poste,Date_de_publication,Identifiant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Lancement du scrappeur </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "Scrappeur(metiers[metier],loc)\n",
    "name_csv = f\"{metier}_{loc}_{now.strftime('%d%m%Y')}.csv\"\n",
    "df = pd.DataFrame(dictionnaire) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Relance du scrappeur si pb  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relance()\n",
    "#df = pd.DataFrame(dictionnaire) \n",
    "#name_csv = f\"{metier}_{loc}_{now.strftime('%d%m%Y')}.csv\"\n",
    "#df.to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Dataframe et Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop_duplicates(subset=['Identifiant','Titre'], keep=\"first\")\n",
    "masque = df['Descriptif_du_poste'] != 'vide'\n",
    "df = df.loc[masque]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Recuperation date à partir description et transformation dans le bon format </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = Recup_date(df['Date_de_publication'],df['Descriptif_du_poste'])\n",
    "date = Correction_date(date)\n",
    "df['Date_de_publication'] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperation experiences à partir de la description \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Experiences'] = df[\"Titre\"].apply(Recup_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperation type de contrat à partir de la description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contrat'] = df['Descriptif_du_poste'].apply(Recup_type_contrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{loc}/{name_csv}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> BDD Mongo </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='localhost', port=27017)\n",
    "db=client.tech_jobs\n",
    "\n",
    "try:\n",
    "    data = pd.DataFrame(list(db.indeed_jobs.find({},{\"_id\":0})))\n",
    "    cols = df.columns\n",
    "    data = data[cols]\n",
    "    df = pd.concat([df,data],axis=0)\n",
    "    df = df.drop_duplicates(subset=['Identifiant','Titre'], keep=\"first\")\n",
    "    #df.to_csv('indeed_jobs.csv',index=False)\n",
    "    db.indeed_jobs.drop()\n",
    "    collection = db.indeed_jobs.insert_many(df.to_dict('records'))\n",
    "    \n",
    "except:\n",
    "\n",
    "    collection = db.indeed_jobs.insert_many(df.to_dict('records'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
