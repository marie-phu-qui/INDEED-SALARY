{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Projet Scraper indeed </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Librairies </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "now = datetime.now()\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from time import sleep\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Fonctions scrapping  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debug_pop():\n",
    "    ''' Fonction permettant le debug lors d un POP'''\n",
    "    sleep(2)\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"popover-x\"]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def Metier(string):\n",
    "    ''' \n",
    "    Fonction permettant de scrapper le métier choisi\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()   \n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"text-input-what\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(2)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    Debug_pop()\n",
    "    browser.find_element_by_xpath('//*[@id=\"refineresults\"]/div[1]/span[2]/a').click()\n",
    "    Debug_pop()\n",
    "\n",
    "        \n",
    "\n",
    "def Localisation(string):\n",
    "    ''' \n",
    "    Fonction permettant de scrapper la localisation choisie\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()\n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"where\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(2)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    Debug_pop()\n",
    "    \n",
    "def Type_Contrat(string):\n",
    "    \n",
    "    ''' \n",
    "    Fonction permettant de scrapper le contrat choisi\n",
    "    input = string\n",
    "        \n",
    "    '''\n",
    "    Debug_pop()\n",
    "    \n",
    "    if string.lower() == 'cdi':      \n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[1]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps plein':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[2]/a/span[1]\").click()\n",
    "    if string.lower() == 'stage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[3]/a/span[1]\").click()\n",
    "    if string.lower() == 'cdd':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[4]/a/span[1]\").click()\n",
    "    if string.lower() == 'apprentissage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[5]/a/span[1]\").click()\n",
    "    if string.lower() == 'contrat pro':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[6]/a/span[1]\").click()\n",
    "    if string.lower() == 'freelance / indépendant':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[7]/a/span[1]\").click()\n",
    "    if string.lower() == 'intérim':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[8]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps partiel':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[9]/a/span[1]\").click()    \n",
    "    Debug_pop()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Scrappeur(metier,localisation):\n",
    "    \n",
    "    ''' \n",
    "     Focntion permettant de scrapper les pages \n",
    "    '''\n",
    "    \n",
    "    browser.get('https://www.indeed.fr/')\n",
    "    browser.maximize_window()\n",
    "    \n",
    "\n",
    "    \n",
    "    Metier(metier)\n",
    "    Localisation(localisation)\n",
    "    \n",
    "    #Titre = []\n",
    "    #Nom_Entreprise = []\n",
    "    #Adresse = []\n",
    "    #Salaire = []\n",
    "    #Descriptif_du_poste = []\n",
    "    #Date_de_publication = []\n",
    "    #Identifiant = []\n",
    "\n",
    "\n",
    "    while True:\n",
    "        Debug_pop()\n",
    "        annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "        for i in range(0,len(annonces)):\n",
    "            try:\n",
    "                titre = annonces[i].find_element_by_class_name('title')\n",
    "                Titre.append(titre.text)\n",
    "            except:\n",
    "                Titre.append('vide')\n",
    "            try:\n",
    "                nom = annonces[i].find_element_by_class_name('company')\n",
    "                Nom_Entreprise.append(nom.text)\n",
    "\n",
    "            except:\n",
    "                Nom_Entreprise.append('vide')\n",
    "            try:\n",
    "                adresse= annonces[i].find_element_by_class_name('location')\n",
    "                Adresse.append(adresse.text)\n",
    "            except:\n",
    "                Adresse.append('vide')\n",
    "            try:\n",
    "                date = annonces[i].find_element_by_class_name('date')\n",
    "                Date_de_publication.append(date.text)\n",
    "\n",
    "            except:\n",
    "                Date_de_publication.append('vide')\n",
    "            try:\n",
    "                salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "                Salaire.append(salaire.text)\n",
    "            except:\n",
    "                Salaire.append('vide')\n",
    "                \n",
    "            try:\n",
    "                annonces[i].find_element_by_class_name('title').click()\n",
    "                Debug_pop()\n",
    "                descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "                Descriptif_du_poste.append(descriptif.text)\n",
    "\n",
    "\n",
    "            except:\n",
    "                Descriptif_du_poste.append('vide')\n",
    "                \n",
    "            try:\n",
    "                    identifiant = browser.current_url\n",
    "                    pos1 = identifiant.find(\"vjk\")\n",
    "                    identifiant = identifiant[pos1:]\n",
    "                    Identifiant.append(identifiant)\n",
    "            except:\n",
    "                    Identifiant.append('vide')\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "            #for i in browser.find_elements_by_class_name(\"np\"):\n",
    "               # if i.text == 'Suivant »':\n",
    "                 #   i.click()\n",
    "        except:\n",
    "            break\n",
    "    df = pd.DataFrame(dictionnaire) \n",
    "    \n",
    "    \n",
    "    #dictionnaire = {\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "    #            \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\n",
    "    #            \"Date_de_publication\":Date_de_publication,\"Date\":Correction_date(Date_de_publication),\n",
    "    #            \"métier_sc\": metier,\"loc_sc\":localisation,\"Date_sc\": now.strftime(\"%d/%m/%Y\") ,\n",
    "    #            #\"heure_sc\": now.strftime(\"%H:%M:%S\"),\n",
    "    #            \"Identifiant\": Identifiant}\n",
    "\n",
    "    #df = pd.DataFrame(dictionnaire) \n",
    "    ##name_csv = f\"indeed_{metier}_{localisation}.csv\"\n",
    "    #df.to_csv(\"indeed_data_engineer_Nantes.csv\",index=False)\n",
    "    #return df\n",
    "    \n",
    "\n",
    "def Relance():\n",
    "    \n",
    "    while True:\n",
    "        Debug_pop()\n",
    "        annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "        for i in range(0,len(annonces)):\n",
    "            \n",
    "            try:\n",
    "                titre = annonces[i].find_element_by_class_name('title')\n",
    "                Titre.append(titre.text)\n",
    "            except:\n",
    "                Titre.append('vide')\n",
    "            try:\n",
    "                nom = annonces[i].find_element_by_class_name('company')\n",
    "                Nom_Entreprise.append(nom.text)\n",
    "\n",
    "            except:\n",
    "                Nom_Entreprise.append('vide')\n",
    "            try:\n",
    "                adresse= annonces[i].find_element_by_class_name('location')\n",
    "                Adresse.append(adresse.text)\n",
    "            except:\n",
    "                Adresse.append('vide')\n",
    "            try:\n",
    "                date = annonces[i].find_element_by_class_name('date')\n",
    "                Date_de_publication.append(date.text)\n",
    "\n",
    "            except:\n",
    "                Date_de_publication.append('vide')\n",
    "            try:\n",
    "                salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "                Salaire.append(salaire.text)\n",
    "            except:\n",
    "                Salaire.append('vide')\n",
    "\n",
    "            try:\n",
    "                annonces[i].find_element_by_class_name('title').click()\n",
    "                Debug_pop()\n",
    "                descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "                Descriptif_du_poste.append(descriptif.text)\n",
    "\n",
    "\n",
    "            except:\n",
    "                Descriptif_du_poste.append('vide')\n",
    "\n",
    "            try:\n",
    "                    identifiant = browser.current_url\n",
    "                    pos1 = identifiant.find(\"vjk\")\n",
    "                    identifiant = identifiant[pos1:]\n",
    "                    Identifiant.append(identifiant)\n",
    "            except:\n",
    "                    Identifiant.append('vide')\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "            \n",
    "        except:\n",
    "            break\n",
    "    df = pd.DataFrame(dictionnaire) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Fonctions preprocessing  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correction_date(liste):\n",
    "    ''' \n",
    "    Fonction permettant de corriger les dates de publications \n",
    "    example : il y a 2 jours en 05/10/2019 si now = 07/10/2019  \n",
    "    input = liste\n",
    "    output = liste\n",
    "        \n",
    "    '''\n",
    "    liste_corr = []\n",
    "    for i in liste:\n",
    "        try:\n",
    "            \n",
    "            jours = 0\n",
    "            mois = 0\n",
    "            annees = 0 \n",
    "            if 'jour' in i:\n",
    "                jours = int(re.findall('\\d+',i)[0])\n",
    "                d = datetime.today() + relativedelta(days=-jours)\n",
    "                d =d.strftime(\"%d/%m/%Y\")\n",
    "            elif 'mois' in i :\n",
    "                mois =  int(re.findall('\\d+',i)[0])\n",
    "                d = datetime.today() + relativedelta(months=-mois)\n",
    "                d =d.strftime(\"%d/%m/%Y\")\n",
    "            else:\n",
    "                d = 'vide'\n",
    "            liste_corr.append(d)\n",
    "        except:\n",
    "            liste_corr.append('vide')\n",
    "    return liste_corr\n",
    "\n",
    "def Recuperation_date_description(liste1,liste2):\n",
    "    '''\n",
    "    Fonction permettant de recuperer les strings entre deux mots pour chaque ele de la liste 2:\"description ici\"\n",
    "    et remplir les ele = 'vide' de la liste 1: \"date_publication ici\" via une liste corrigé\n",
    "    \n",
    "    '''\n",
    "    liste_corr = []\n",
    "    for i,j in zip(liste1,liste2):\n",
    "        if (i == \"vide\") and (j.find('jours') > 0 ):\n",
    "            \n",
    "            deb = j.find('il y a ')\n",
    "            fin = j.find('jours')\n",
    "            temp = j[deb:fin+5]\n",
    "            liste_corr.append(temp)\n",
    "            \n",
    "        elif (i == \"vide\") and (j.find('mois') > 0 ):\n",
    "            \n",
    "            deb = i.find('il y a ')\n",
    "            fin = i.find('mois')\n",
    "            temp = j[deb:fin+5]\n",
    "            liste_corr.append(temp)\n",
    "            \n",
    "        elif (i == \"vide\") and ((j.find('mois') < 0) or (j.find('jours') < 0 )):\n",
    "                                \n",
    "            liste_corr.append(i)\n",
    "\n",
    "        else:\n",
    "            liste_corr.append(i)\n",
    "\n",
    "    return liste_corr    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Scrapping </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3700d3170e8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;34m\"Salaire\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mSalaire\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Descriptif_du_poste\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mDescriptif_du_poste\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;34m\"Date_de_publication\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mDate_de_publication\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"métier_sc\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[1;34m\"loc_sc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Date_sc\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d/%m/%Y\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[1;31m#\"heure_sc\": now.strftime(\"%H:%M:%S\"),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \"Identifiant\": Identifiant}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'now' is not defined"
     ]
    }
   ],
   "source": [
    "Titre = []\n",
    "Nom_Entreprise = []\n",
    "Adresse = []\n",
    "Salaire = []\n",
    "Descriptif_du_poste = []\n",
    "Date_de_publication = []\n",
    "Identifiant = []\n",
    "metier = ''\n",
    "loc = ''\n",
    "\n",
    "dictionnaire = {\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "                \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\n",
    "                \"Date_de_publication\":Date_de_publication,\"métier_sc\": metier,\n",
    "                \"loc_sc\":loc,\"Date_sc\": now.strftime(\"%d/%m/%Y\") ,\n",
    "                #\"heure_sc\": now.strftime(\"%H:%M:%S\"),\n",
    "                \"Identifiant\": Identifiant}\n",
    "\n",
    "df = pd.DataFrame(dictionnaire) \n",
    "#####################\n",
    "\n",
    "metiers = {\n",
    "           'Data_scientist': 'title:(\"data scientist\" or \"data science\" or \"machine learning\" or \"deep learning\")',\n",
    "           'Data_analyst'  : 'title:(\"data analyst\" or \"data analyste\" or \"data analysis\" or \"data analytics\")',\n",
    "           'Data_architect': 'title:(\"data architecte\" or \"data architect\")',\n",
    "           'Data_engineer' : 'title:(\"data engineer\" )',\n",
    "           'Big_data'      : 'title:(\"big data\")',\n",
    "           'Autres_metiers_data' : 'title:data -scientist -analyst -engineer -\"big data\" -architecte',\n",
    "           'développeur':     'title:développeur -data'\n",
    "           'BI'          :     'title:(développeur or developer) -data -business -affaire -toiles -bi'\n",
    "           \n",
    "           }\n",
    "\n",
    "Localisations = [\"Paris\",\"Lyon\", \"Toulouse\", \"Nantes\",\"Bordeaux\"]\n",
    "#columns = [Titre,Nom_Entreprise,Adresse,Salaire,Descriptif_du_poste,Date_de_publication,Identifiant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Lancement du scrappeur </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "metier = 'développeur'\n",
    "loc = 'Paris'\n",
    "Scrappeur(metiers[metier],loc)\n",
    "name_csv = f\"{metier}_{loc}_{now.strftime('%d%m%Y')}.csv\"\n",
    "df = pd.DataFrame(dictionnaire) \n",
    "df.to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Relance du scrappeur si pb  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Relance()\n",
    "df = pd.DataFrame(dictionnaire) \n",
    "name_csv = f\"{metier}_{loc}_{now.strftime('%d%m%Y')}.csv\"\n",
    "df.to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Dataframe et Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliser les fonctions au debut et d autres à rajouter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> BDD Mongo </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='localhost', port=27017)\n",
    "db=client.tech_jobs\n",
    "\n",
    "try:\n",
    "    data = pd.DataFrame(list(db.indeed_jobs.find({},{\"_id\":0})))\n",
    "    cols = df.columns\n",
    "    data = data[cols]\n",
    "    df = pd.concat([df,data],axis=0)\n",
    "    df = df.drop_duplicates(subset=['Identifiant','Titre'], keep=\"first\")\n",
    "    #df.to_csv('indeed_jobs.csv',index=False)\n",
    "    db.indeed_jobs.drop()\n",
    "    collection = db.indeed_jobs.insert_many(df.to_dict('records'))\n",
    "    \n",
    "except:\n",
    "\n",
    "    collection = db.indeed_jobs.insert_many(df.to_dict('records'))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
