{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Projet Scraper indeed </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.indeed.fr/')\n",
    "browser.maximize_window()\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire un script de scraping sur indeed (https://www.indeed.fr/)  qui permette à l’user de spécifier le type d’annonces qu’il souhaite récupérer :\n",
    "-\tMétier (développeur, data scientist…)\n",
    "-\tType de contrat recherché (CDI, CDD, freelance…)\n",
    "-\tLieu de recherche (Paris, Toulouse, …)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metier(string):\n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"text-input-what\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(3)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "\n",
    "def Localisation(string):\n",
    "    recherche = browser.find_element_by_xpath('//*[@id=\"where\"]')\n",
    "    recherche.click()\n",
    "    recherche.clear()\n",
    "    recherche.send_keys(string)\n",
    "    sleep(3)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    \n",
    "def Type_Contrat(string):\n",
    "    if string.lower() == 'cdi':      \n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[1]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps plein':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[2]/a/span[1]\").click()\n",
    "    if string.lower() == 'stage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[3]/a/span[1]\").click()\n",
    "    if string.lower() == 'cdd':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[4]/a/span[1]\").click()\n",
    "    if string.lower() == 'apprentissage':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[5]/a/span[1]\").click()\n",
    "    if string.lower() == 'contrat pro':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[6]/a/span[1]\").click()\n",
    "    if string.lower() == 'freelance / indépendant':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[7]/a/span[1]\").click()\n",
    "    if string.lower() == 'intérim':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[8]/a/span[1]\").click()\n",
    "    if string.lower() == 'temps partiel':\n",
    "        browser.find_element_by_xpath(\"//*[@id='JOB_TYPE_rbo']/ul/li[9]/a/span[1]\").click()    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les infos à scraper :\n",
    "-\tTitre\n",
    "-\tNom de la boite\n",
    "-\tAdresse\n",
    "-\tSalaire\n",
    "-\tDescriptif du poste\n",
    "-\tDate de publication de l’annonce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liste  à remplir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metier(\"data scientist\")\n",
    "Localisation(\"Paris\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type_Contrat('cdi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation des listes vides pour chaque colonne**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "Titre = []\n",
    "Nom_Entreprise = []\n",
    "Adresse = []\n",
    "Salaire = []\n",
    "Descriptif_du_poste = []\n",
    "Date_de_publication = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    annonces = browser.find_elements_by_class_name(\"jobsearch-SerpJobCard\")\n",
    "    for i in range(0,len(annonces)):\n",
    "        try:\n",
    "            titre = annonces[i].find_element_by_class_name('title')\n",
    "            Titre.append(titre.text)\n",
    "        except:\n",
    "            Titre.append('vide')\n",
    "        try:\n",
    "            nom = annonces[i].find_element_by_class_name('company')\n",
    "            Nom_Entreprise.append(nom.text)\n",
    "\n",
    "        except:\n",
    "            Nom_Entreprise.append('vide')\n",
    "        try:\n",
    "            adresse= annonces[i].find_element_by_class_name('location')\n",
    "            Adresse.append(adresse.text)\n",
    "        except:\n",
    "            Adresse.append('vide')\n",
    "        try:\n",
    "            date = annonces[i].find_element_by_class_name('date')\n",
    "            Date_de_publication.append(date.text)\n",
    "\n",
    "        except:\n",
    "            Date_de_publication.append('vide')\n",
    "        try:\n",
    "            salaire = annonces[i].find_element_by_class_name('salaryText')\n",
    "            Salaire.append(salaire.text)\n",
    "        except:\n",
    "            Salaire.append('vide')\n",
    "        try:\n",
    "            annonces[i].find_element_by_class_name('title').click()\n",
    "            sleep(2)\n",
    "            descriptif= browser.find_element_by_xpath(\"//*[@id='vjs-content']\")\n",
    "            Descriptif_du_poste.append(descriptif.text)\n",
    "        except:\n",
    "            Descriptif_du_poste.append('vide')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        browser.find_element_by_xpath(\"//*[contains(text(), 'Suivant')]\").click() \n",
    "        sleep(2)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Titre\":Titre,\"Nom_Entreprise\":Nom_Entreprise,\"Adresse\":Adresse,\n",
    "                  \"Salaire\":Salaire,\"Descriptif_du_poste\":Descriptif_du_poste,\"Date_de_publication\":Date_de_publication}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrapping et remplissage des listes utiles pour le remplissage du df par la suite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remplissage du dataframe et nettoyage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enregistrement des données dans BDD mongo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brouillon avec beautifulsoup**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
